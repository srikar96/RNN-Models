{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We use a Many to one architecture to model sentiment classification. There are many appliations, in this particular one I chose movie review classification.\n",
    "\n",
    "In this particular notebook, I've used an LSTM as the choice of RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import bs4\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "I've used an IMDB dataset which contains movie reviews and the associated sentiment i.e if the review is positive or negative. The dataset contains 50000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Convert the semtiment column to 0 and 1 for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the HTML tags and stop words in the reviews column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def clean_data(text):\n",
    "    soup = bs4.BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern,'',text)\n",
    "    text = text.lower()\n",
    "    for i in stopwords:\n",
    "        text = text.replace(' ' + i + ' ', ' ')\n",
    "        text = text.replace('  ', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production filming techniqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewers mentioned watching just 1 oz epi...          1\n",
       "1  a wonderful little production filming techniqu...          1\n",
       "2  i thought wonderful way spend time hot summer ...          1\n",
       "3  basically theres family little boy jake thinks...          0\n",
       "4  petter matteis love time money visually stunni...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test: 40000 for training and 10000 for testing\n",
    "data = list(df['review'])\n",
    "labels = list(df['sentiment'])\n",
    "\n",
    "train_X = data[:40000]\n",
    "test_X = data[40000:]\n",
    "labels_X = labels[:40000]\n",
    "labels_Y = labels[40000:]\n",
    "\n",
    "word_cap = 25000 #Use only the top 25000 words to tokenize the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer creates tokens for the corpus which can be accessed by tokenizer.index. Using the texts_to_sequences() method maps the text into integer tokens. oov_token used for out of vocabulary words, its index is vocab_count + 1.  \n",
    "\n",
    "To make sure all the sentences are of the same length, we post pad the sequences with zeoros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>', num_words=word_cap)\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "train_idx = tokenizer.word_index\n",
    "train_idx_rev = {i[1]:i[0] for i in train_idx.items()}\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(train_X)\n",
    "test_seq = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "train_seq = tf.keras.preprocessing.sequence.pad_sequences(train_seq, padding='post')\n",
    "test_seq = tf.keras.preprocessing.sequence.pad_sequences(test_seq, maxlen=train_seq.shape[1], padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1437)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.shape # (num of examples, length of each sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The first model consists of an Embedding layer which is not pretrained, it is trained on the fly with the current data i.e the Embedding weight matrix is updated by backproagation while training on the current data.\n",
    "\n",
    "The next layer consists of 32 bidirectional LSTMs followed bya dense layer to classify the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(train_seq.shape[1],))\n",
    "x = tf.keras.layers.Embedding(word_cap, 100, input_length=train_seq.shape[1])(inputs)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1437)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1437, 100)         2500000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1437, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,534,113\n",
      "Trainable params: 2,534,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 568s 14ms/sample - loss: 0.5420 - accuracy: 0.7211 - val_loss: 0.3926 - val_accuracy: 0.8460\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 569s 14ms/sample - loss: 0.2915 - accuracy: 0.8904 - val_loss: 0.2711 - val_accuracy: 0.8944\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 570s 14ms/sample - loss: 0.1826 - accuracy: 0.9388 - val_loss: 0.2955 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3ad356710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_seq, np.array(labels_X), validation_data=(test_seq, np.array(labels_Y)), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model_many_one.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_many_one.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to test on a few custom sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_test(dat, mod):\n",
    "    for i in range(len(dat)):\n",
    "        dat[i] = dat[i].split()\n",
    "    dat = tokenizer.texts_to_sequences(dat)\n",
    "    dat = tf.keras.preprocessing.sequence.pad_sequences(dat, maxlen=1437, padding='post')\n",
    "    res = mod.predict(dat)\n",
    "    return ['positive' if i >= 0.5 else 'negative' for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = custom_test([\"I love the movie\", \"the movie is okayish\", \" Super film\", \"movie is not that great\", \"Not a bad film\"], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "This model is the same as the above but here I'm using pretrained GloVe vectors for the Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = {}\n",
    "with open ('/home/srikar/datasets/glove/glove.6B.100d.txt', 'r') as file:\n",
    "    for i in file:\n",
    "        temp = i.split()\n",
    "        vecs[temp[0]] = temp[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Embedding matrix, load the weights from the pretrained corpus of words. \n",
    "embeddings_matrix = np.zeros((word_cap, 100));\n",
    "        \n",
    "for i in range(1,word_cap):\n",
    "    embedding_vector = vecs.get(train_idx_rev[i])\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(train_seq.shape[1],))\n",
    "x = tf.keras.layers.Embedding(word_cap, 100, input_length=train_seq.shape[1], weights=[embeddings_matrix], trainable=False)(inputs)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "model_new = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1437)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1437, 100)         2500000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1437, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                34048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,534,113\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary() # The number of trainable parameters reduce significantly as we are using pretrained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 498s 12ms/sample - loss: 0.5890 - accuracy: 0.6906 - val_loss: 0.4882 - val_accuracy: 0.7803\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 478s 12ms/sample - loss: 0.4925 - accuracy: 0.7711 - val_loss: 0.4289 - val_accuracy: 0.8211\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 478s 12ms/sample - loss: 0.4455 - accuracy: 0.7990 - val_loss: 0.3768 - val_accuracy: 0.8373\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 480s 12ms/sample - loss: 0.4248 - accuracy: 0.8122 - val_loss: 0.3484 - val_accuracy: 0.8489\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 481s 12ms/sample - loss: 0.4090 - accuracy: 0.8203 - val_loss: 0.3536 - val_accuracy: 0.8524\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 475s 12ms/sample - loss: 0.3939 - accuracy: 0.8275 - val_loss: 0.3376 - val_accuracy: 0.8553\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 473s 12ms/sample - loss: 0.3916 - accuracy: 0.8285 - val_loss: 0.3348 - val_accuracy: 0.8541\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 470s 12ms/sample - loss: 0.3840 - accuracy: 0.8323 - val_loss: 0.3187 - val_accuracy: 0.8656\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 497s 12ms/sample - loss: 0.3747 - accuracy: 0.8377 - val_loss: 0.3332 - val_accuracy: 0.8575\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 541s 14ms/sample - loss: 0.3673 - accuracy: 0.8409 - val_loss: 0.3284 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd1f5f3dcf8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(train_seq, np.array(labels_X), validation_data=(test_seq, np.array(labels_Y)), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = custom_test([\"I love the movie\", \"the movie is okayish\", \" Super film\", \"movie is not that great\", \"Not a bad film\"], model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
